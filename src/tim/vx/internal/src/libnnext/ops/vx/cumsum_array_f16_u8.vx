#include "cl_viv_vx_ext.h"

_viv_uniform VXC_512Bits uniAccSumVertF16toF16_2x8;
_viv_uniform VXC_512Bits uniSumHorzF16toF16A_4x4;
_viv_uniform VXC_512Bits uniSumHorzF16toF16B_4x4;
_viv_uniform VXC_512Bits uniSumHorzF16toF16C_2x8;
_viv_uniform VXC_512Bits uniAccSumHorzF16toF16_2x8;

_viv_uniform VXC_512Bits uniSetZeroF16_2x8;

_viv_uniform int width;
_viv_uniform int height;
_viv_uniform int channel;

_viv_uniform int2 multAndoutZP0;//[0:15] multiplier, [31:63] output zp
_viv_uniform VXC_512Bits uniU8MulAndPostShift_0_Lo_2x8;

_viv_uniform int remainder;
_viv_uniform int w_size;


#define CUMSUM_ARRAY_F16TOQINT_AXIS2(out_name, src_type, dst_type, stride_out) \
__kernel void cumsum_array_F16to##out_name##_axis2( \
    __read_only image2d_array_t   input, \
    __write_only image2d_array_t  output, \
    int axis, int exclusive, int rev \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
 \
    vxc_short8 src; \
    dst_type dst; \
    vxc_half8 data, sum; \
    VXC_DP2x8(sum, sum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSetZeroF16_2x8); \
    vxc_ushort8 ms0; \
    _viv_asm(COPY, ms0, multAndoutZP0, 16); \
    Tensor img1 = create_tensor_from_image2d_array(input, 2); \
    Tensor img2 = create_tensor_from_image2d_array(output, stride_out); \
    if (coord.x == ((w_size >> 3) * 8) && remainder != 0) \
    { \
        coord.x = coord.x - (8 - remainder); \
    } \
    for(coord.z = 0; coord.z < channel; coord.z++) \
    { \
        uchar* input_ptr = get_tensor_ptr_from_coord(img1, coord); \
        uchar* output_ptr = get_tensor_ptr_from_coord(img2, coord); \
        __global vxc_short8* in_ptr = (__global vxc_short8*)input_ptr; \
        __global dst_type* out_ptr = (__global dst_type*)output_ptr; \
        src = in_ptr[0]; \
        _viv_asm(COPY, data, src, 16); \
 \
        VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                uniU8MulAndPostShift_0_Lo_2x8); \
        out_ptr[0] = dst; \
    } \
}
CUMSUM_ARRAY_F16TOQINT_AXIS2(I8,  vxc_half8, vxc_char16, 1)
CUMSUM_ARRAY_F16TOQINT_AXIS2(I16, vxc_half8, vxc_short8, 2)
CUMSUM_ARRAY_F16TOQINT_AXIS2(U8,  vxc_half8, vxc_uchar16, 1)


#define CUMSUM_ARRAY_F16TOQINT_AXIS1(out_name, src_type, dst_type, stride_out) \
__kernel void cumsum_array_F16to##out_name##_axis1( \
    __read_only image2d_array_t   input, \
    __write_only image2d_array_t  output, \
    int axis, int exclusive, int rev \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
 \
    vxc_short8 src; \
    dst_type dst; \
    vxc_half8 data, sum; \
    VXC_DP2x8(sum, sum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSetZeroF16_2x8); \
    vxc_ushort8 ms0; \
    _viv_asm(COPY, ms0, multAndoutZP0, 16); \
    Tensor img1 = create_tensor_from_image2d_array(input, 2); \
    Tensor img2 = create_tensor_from_image2d_array(output, stride_out); \
    if (coord.x == ((w_size >> 3) * 8) && remainder != 0) \
    { \
        coord.x = coord.x - (8 - remainder); \
    } \
    for(coord.y = 0; coord.y < height; coord.y++) \
    { \
        uchar* input_ptr = get_tensor_ptr_from_coord(img1, coord); \
        uchar* output_ptr = get_tensor_ptr_from_coord(img2, coord); \
        __global vxc_short8* in_ptr = (__global vxc_short8*)input_ptr; \
        __global dst_type* out_ptr = (__global dst_type*)output_ptr; \
        src = in_ptr[0]; \
        _viv_asm(COPY, data, src, 16); \
 \
        VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                uniU8MulAndPostShift_0_Lo_2x8); \
        out_ptr[0] = dst; \
    } \
}
CUMSUM_ARRAY_F16TOQINT_AXIS1(I8,  vxc_half8, vxc_char16, 1)
CUMSUM_ARRAY_F16TOQINT_AXIS1(I16, vxc_half8, vxc_short8, 2)
CUMSUM_ARRAY_F16TOQINT_AXIS1(U8,  vxc_half8, vxc_uchar16, 1)

#define CUMSUM_ARRAY_F16TOQINT_AXIS0(out_name, src_type, dst_type, stride_out) \
__kernel void cumsum_array_F16to##out_name##_axis0( \
    __read_only image2d_array_t   input, \
    __write_only image2d_array_t  output, \
    int axis, int exclusive, int rev \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
 \
    vxc_short8 src; \
    dst_type dst; \
    vxc_half8 data, tmpsum, sum; \
    VXC_DP2x8(sum, sum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSetZeroF16_2x8); \
    vxc_ushort8 ms0; \
    _viv_asm(COPY, ms0, multAndoutZP0, 16); \
    Tensor img1 = create_tensor_from_image2d_array(input, 2); \
    Tensor img2 = create_tensor_from_image2d_array(output, stride_out); \
    for(; coord.x < width; coord.x += 8) \
    { \
        if (coord.x == ((w_size >> 3) * 8) && remainder != 0) \
        { \
            coord.x = coord.x - (8 - remainder); \
        } \
        uchar* input_ptr = get_tensor_ptr_from_coord(img1, coord); \
        uchar* output_ptr = get_tensor_ptr_from_coord(img2, coord); \
        __global vxc_short8* in_ptr = (__global vxc_short8*)input_ptr; \
        __global dst_type* out_ptr = (__global dst_type*)output_ptr; \
        src = in_ptr[0]; \
        _viv_asm(COPY, data, src, 16); \
 \
        VXC_DP4x4(tmpsum, data, data, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniSumHorzF16toF16A_4x4); \
        VXC_DP4x4(tmpsum, data, data, VXC_MODIFIER(4, 7, 0, VXC_RM_TowardZero, 0), uniSumHorzF16toF16B_4x4); \
        VXC_DP2x8(tmpsum, tmpsum, tmpsum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSumHorzF16toF16C_2x8); \
        VXC_DP2x8(sum, tmpsum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumHorzF16toF16_2x8); \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                uniU8MulAndPostShift_0_Lo_2x8); \
        out_ptr[0] = dst; \
    } \
}
CUMSUM_ARRAY_F16TOQINT_AXIS0(I8,  vxc_half8, vxc_char16, 1)
CUMSUM_ARRAY_F16TOQINT_AXIS0(I16, vxc_half8, vxc_short8, 2)
CUMSUM_ARRAY_F16TOQINT_AXIS0(U8,  vxc_half8, vxc_uchar16, 1)

#define CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS2(out_name, src_type, dst_type, stride_out) \
__kernel void cumsum_array_ex_rev_F16to##out_name##_axis2( \
    __read_only image2d_array_t   input, \
    __write_only image2d_array_t  output, \
    int axis, int exclusive, int rev \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), 0, 0); \
 \
    vxc_short8 src; \
    dst_type dst; \
    vxc_half8 data, sum; \
    VXC_DP2x8(sum, sum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSetZeroF16_2x8); \
    vxc_ushort8 ms0; \
    _viv_asm(COPY, ms0, multAndoutZP0, 16); \
    if (coord.x == ((w_size >> 3) * 8) && remainder != 0) \
    { \
        coord.x = coord.x - (8 - remainder); \
    } \
    Tensor img1 = create_tensor_from_image2d_array(input, 2); \
    Tensor img2 = create_tensor_from_image2d_array(output, stride_out); \
    uchar* input_ptr = get_tensor_ptr_from_coord(img1, coord); \
    uchar* output_ptr = get_tensor_ptr_from_coord(img2, coord); \
    __global vxc_short8* in_ptr = (__global vxc_short8*)input_ptr; \
    __global dst_type* out_ptr = (__global dst_type*)output_ptr; \
    if(exclusive == 0 && rev) \
    { \
        for(coord.z = channel - 1; coord.z >= 0; coord.z--) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            out_ptr = (__global dst_type*)output_ptr; \
            src = in_ptr[0]; \
            _viv_asm(COPY, data, src, 16); \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
    else if(exclusive && rev == 0) \
    { \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
        out_ptr[0] = dst; \
        for(; coord.z < channel - 1;) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            src = in_ptr[0]; \
            coord.z++; \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            out_ptr = (__global dst_type*)output_ptr; \
            _viv_asm(COPY, data, src, 16); \
     \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
    else if(exclusive && rev) \
    { \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
        coord.z = channel - 1; \
        output_ptr = get_tensor_ptr_from_coord(img2, coord); \
        out_ptr = (__global dst_type*)output_ptr; \
        out_ptr[0] = dst; \
        for(; coord.z > 0;) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            src = in_ptr[0]; \
            coord.z--; \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            out_ptr = (__global dst_type*)output_ptr; \
            _viv_asm(COPY, data, src, 16); \
     \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
}
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS2(I8,  vxc_half8, vxc_char16, 1)
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS2(I16, vxc_half8, vxc_short8, 2)
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS2(U8,  vxc_half8, vxc_uchar16, 1)

#define CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS1(out_name, src_type, dst_type, stride_out) \
__kernel void cumsum_array_ex_rev_F16to##out_name##_axis1( \
    __read_only image2d_array_t   input, \
    __write_only image2d_array_t  output, \
    int axis, int exclusive, int rev \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), 0, get_global_id(2), 0); \
 \
    vxc_short8 src; \
    dst_type dst; \
    vxc_half8 data, sum; \
    VXC_DP2x8(sum, sum, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniSetZeroF16_2x8); \
    vxc_ushort8 ms0; \
    _viv_asm(COPY, ms0, multAndoutZP0, 16); \
    if (coord.x == ((w_size >> 3) * 8) && remainder != 0) \
    { \
        coord.x = coord.x - (8 - remainder); \
    } \
    Tensor img1 = create_tensor_from_image2d_array(input, 2); \
    Tensor img2 = create_tensor_from_image2d_array(output, stride_out); \
    uchar* input_ptr = get_tensor_ptr_from_coord(img1, coord); \
    uchar* output_ptr = get_tensor_ptr_from_coord(img2, coord); \
    __global vxc_short8* in_ptr = (__global vxc_short8*)input_ptr; \
    __global dst_type* out_ptr = (__global dst_type*)output_ptr; \
    if(exclusive == 0 && rev) \
    { \
        for(coord.y = height - 1; coord.y >= 0; coord.y--) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            out_ptr = (__global dst_type*)output_ptr; \
            src = in_ptr[0]; \
            _viv_asm(COPY, data, src, 16); \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
    else if(exclusive && rev == 0) \
    { \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
        out_ptr[0] = dst; \
        for(; coord.y < height - 1;) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            src = in_ptr[0]; \
            coord.y++; \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            out_ptr = (__global dst_type*)output_ptr; \
            _viv_asm(COPY, data, src, 16); \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
    else if(exclusive && rev) \
    { \
        VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
        coord.y = height - 1; \
        output_ptr = get_tensor_ptr_from_coord(img2, coord); \
        out_ptr = (__global dst_type*)output_ptr; \
        out_ptr[0] = dst; \
        for(; coord.y > 0;) \
        { \
            input_ptr = get_tensor_ptr_from_coord(img1, coord); \
            in_ptr = (__global vxc_short8*)input_ptr; \
            src = in_ptr[0]; \
            coord.y--; \
            output_ptr = get_tensor_ptr_from_coord(img2, coord); \
            out_ptr = (__global dst_type*)output_ptr; \
            _viv_asm(COPY, data, src, 16); \
            VXC_DP2x8(sum, data, sum, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniAccSumVertF16toF16_2x8); \
            VXC_DP2x8(dst, sum, ms0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), \
                    uniU8MulAndPostShift_0_Lo_2x8); \
            out_ptr[0] = dst; \
        } \
    } \
}
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS1(I8,  vxc_half8, vxc_char16, 1)
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS1(I16, vxc_half8, vxc_short8, 2)
CUMSUM_ARRAY_F16TOQINT_EX_REV_AXIS1(U8,  vxc_half8, vxc_uchar16, 1)